---
title: "CUNY SPS DATA 621 - CTG5 - HW1"
author: "Gabrielle Bartomeo, Jeremy O'Brien, Lidiia Tronina, Rose Koh, Betsy Rosalen"
date: "February 27, 2019"
output:
    pdf_document:
        toc: true
        toc_depth: 2
        number_sections: true
        fig_width: 8
        fig_height: 8
        fig_caption: true
        highlight: haddock
        df_print: kable

        #css: ./reports.css
---

```{r setup, include=FALSE}
library(tufte)
library(ggplot2)
library(kableExtra)
library(ggcorrplot)
library(Matrix)
library(gridExtra)
library(tidyverse)
library(scales)
library(MASS)
library(matrixcalc)
library(psych)
library(GGally)
library(ggpubr)
library(leaps)

# I don't think we are actually using all these yet

knitr::opts_chunk$set(tidy = FALSE, echo=FALSE, message=FALSE, warning=FALSE) # <<<<<<<<<< SET UP ALL REPORT CHUNK OPTIONS HERE - invalidates cache when the tufte version changes, sets all chunks to not show any code, warnings, or messages in the body of the report.

options(htmltools.dir.version = FALSE, scipen=999, digits = 5)
options(tibble.print_max = Inf)
set.seed(123)

#source("./source_code/script.R") # <<<<<<<<<< NOTE HERE - sets up the script file
```

# 1. DATA EXPLORATION

### Let's leave instructions in the report for now so that we can easily reference them to make sure we are including everything we need to, cool?

Describe the size and the variables in the mb training data set. Consider that too much detail will cause a manager to lose interest while too little detail will make the manager consider that you aren't doing your job. Some suggestions are given below. Please do NOT treat this as a check list of things to do to complete the assignment. You should have your own thoughts on what to tell the boss. These are just ideas.

a. Mean / Standard Deviation / Median
b. Bar Chart or Box Plot of the data and/or Histograms
c. Is the data correlated to the target variable (or to other variables?)
d. Are any of the variables missing and need to be imputed "fixed"?

```{r}
# Load in data
mb_train <- read.csv("./data/moneyball-training-data.csv")[,-1] # use me
dim(mb_train)
```

```{r}
# Removes all rows with missing data
mb_complete <- mb_train[complete.cases(mb_train),]
Means <- sapply(mb_complete, mean) # We will need these later...
Stan_Dev <- sapply(mb_complete, sd)
```

Printing the entire Summary might be excessive.  Per the instructions, we don't want to "cause a manager to lose interest"... 

```{r}
Data_Summary <- summary(mb_train)
kable(Data_Summary[,1:4], caption = "Summary")
kable(Data_Summary[,5:8])
kable(Data_Summary[,9:12])
kable(Data_Summary[,13:16])
```

## Missing Values

TEAM_BATTING_HBP should be removed sincce most values are missing.  There is no way to fill in those missing values with anything that makes sense.  The Missing Values Table is supposed to be under here... 

```{r}
Missing_values <- sapply(mb_train, function(x) sum(is.na(x)))
kable(Missing_values, caption = "Missing Values by Variable")
```

## Standard Deviation

The Standard Deviation Table is supposed to be under here... 

```{r}
kable(Stan_Dev, caption = "Standard Deviation")
```

## Subheading here

Put some text in here

```{r, fig.height=10, fig.width=8, fig.cap = "Each Predictor vs. Target"}
mb_train %>%
  gather(-TARGET_WINS, key = "var", value = "value") %>%
  ggplot(aes(x = value, y = TARGET_WINS)) +
    geom_point(alpha=0.1) +
    stat_smooth() +
    facet_wrap(~ var, scales = "free", ncol=3) +
    ylab("TARGET_WINS on y-axis") +
    xlab("Predictor Variables on x-axis") +
    ggtitle("Each Predictor vs. Target") + 
    theme(panel.background = element_blank())
```

## Boxplots

Put some text in here

```{r fig.height=5, fig.cap = "Boxplots"}
Boxplots <- ggplot(stack(mb_complete), aes(x=ind, y=values)) +
    geom_boxplot() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
Boxplots
```

## Correlation

Put some text in here

```{r, fig.height=6, fig.cap = "Correlation", fig.fullwidth = TRUE}
Correlation <- ggcorrplot(as.data.frame(round(cor(mb_complete), 3)),
           type="lower", lab=TRUE, lab_size=2)
Correlation
```

## Histograms

Put some text in here

```{r}
Histograms <- mb_train %>%
    gather() %>%
    ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram(fill = "#58BFFF") +
    #xlab("") +
    #ylab("") +
    ggtitle("Histograms") +
    theme(panel.background = element_blank())
Histograms
```

## Pairs

Look for predictors that are correlated with each other...

```{r, fig.height=10}
Pairs <- ggpairs(mb_train[,2:16])
Pairs
```

## Point_plots

Put some text in here

```{r, fig.height=5, fig.cap = "Point Plots"}
Point_plots <- ggplot(data=mb_complete, aes(x=TARGET_WINS)) +
    geom_point(aes(y=TEAM_BATTING_H, color="Base Hits by Batters"), alpha=0.1) +
    geom_point(aes(y=TEAM_BATTING_2B, color="Doubles by Batters"), alpha=0.1) +
    geom_point(aes(y=TEAM_BATTING_3B, color="Triples by Batters"), alpha=0.1) +
    geom_point(aes(y=TEAM_BATTING_HR, color="Homeruns by Batters"), alpha=0.1) +
    geom_point(aes(y=TEAM_BATTING_BB, color="Walks by Batters"), alpha=0.1) +
    geom_point(aes(y=TEAM_BATTING_SO, color="Strikeouts by Batters"), alpha=0.1) +
    geom_point(aes(y=TEAM_BASERUN_SB, color="Stolen Bases"), alpha=0.1) +
    geom_point(aes(y=TEAM_BASERUN_CS, color="Caught Stealing"), alpha=0.1) +
    geom_point(aes(y=TEAM_BATTING_HBP, color="Batters Hit by Pitch"), alpha=0.1) +
    geom_point(aes(y=TEAM_PITCHING_H, color="Hits Allowed"), alpha=0.1) +
    geom_point(aes(y=TEAM_PITCHING_HR, color="Homeruns Allowed"), alpha=0.1) +
    geom_point(aes(y=TEAM_PITCHING_SO, color="Strikeouts by Pitchers"), alpha=0.1) +
    geom_point(aes(y=TEAM_FIELDING_E, color="Errors"), alpha=0.05) +
    geom_point(aes(y=TEAM_FIELDING_DP, color="Double Plays"), alpha=0.1) +
    labs(color="Variables", ylab="Variables")
Point_plots
```

# 2. DATA PREPARATION

Describe how you have transformed the data by changing the original variables or creating new variables. If you did transform the data or create new variables, discuss why you did this. Here are some possible transformations.

a. Fix missing values (maybe with a Mean or Median value)
b. Create flags to suggest if a variable was missing
c. Transform data by putting it into buckets
d. Mathematical transforms such as log or square root
e. Combine variables (such as ratios or adding or multiplying) to create new variables


# 3. BUILD MODELS

Using the training data set, build at least three different multiple linear regression models, using different variables (or the same variables with different transformations). Since we have not yet covered automated variable selection methods, you should select the variables manually (unless you previously learned Forward or Stepwise selection, etc.). Since you manually selected a variable for inclusion into the model or exclusion into the model, indicate why this was done.

Discuss the coefficients in the models, do they make sense? For example, if a team hits a lot of Home Runs, it would be reasonably expected that such a team would win more games. However, if the coefficient is negative (suggesting that the team would lose more games), then that needs to be discussed. Are you keeping the model even though it is counter intuitive? Why? The boss needs to know.

```{r}
# Basic linear model with all variables
mb_lm <- lm(TARGET_WINS ~ ., mb_train)
LM_Summary <- summary(mb_lm)
kable(LM_Summary$coef, caption = "Full Model Coefficients")
```

```{r}
par(mfrow=c(2,2))
LM_plot <- plot(mb_lm)
LM_plot
```

```{r}
# All Subsets Regression from leaps package
Leaps <- regsubsets(x=mb_complete[,2:16], y=mb_complete[,1], nbest=3)
# plot a table of models showing variables in each model.
# models are ordered by the selection statistic.
Leaps_plot <- plot(Leaps, scale="r2")
Leaps_plot
```

```{r}
# Scale all the predictor variables
mb_scaled <- as.data.frame(scale(mb_complete[,2:16], center=Means[2:16], scale=Stan_Dev[2:16]))
mb_scaled$TARGET_WINS <- mb_complete[,1]
# Linear model using all scaled predictors
mb_scaled_lm <- lm(TARGET_WINS ~ ., mb_scaled)
Scaled_LM_Summary <- summary(mb_scaled_lm)
kable(Scaled_LM_Summary$coef, caption = "Full SCALED Model Coefficients")
```

```{r}
par(mfrow=c(2,2))
Scaled_LM_plot <- plot(mb_scaled_lm)
Scaled_LM_plot
```

```{r}
# All Subsets Regression from leaps package on SCALED data
Scaled_Leaps <- regsubsets(x=mb_scaled[,1:15], y=mb_scaled[,16], nbest=3)
# plot a table of models showing variables in each model.
# models are ordered by the selection statistic.
Scaled_Leaps_plot <- plot(Scaled_Leaps, scale="r2")
Scaled_Leaps_plot
```

# 4. SELECT MODELS

Decide on the criteria for selecting the best multiple linear regression model. Will you select a model with slightly worse performance if it makes more sense or is more parsimonious? Discuss why you selected your model.

For the multiple linear regression model, will you use a metric such as Adjusted R2, RMSE, etc.? Be sure to explain how you can make inferences from the model, discuss multi-collinearity issues (if any), and discuss other relevant model output. Using the training data set, evaluate the multiple linear regression model based on (a) mean squared error, (b) R2, (c) F-statistic, and (d) residual plots. Make predictions using the evaluation data set.

# Appendix

```{r echo = TRUE, eval = FALSE}

# <<<<<<<<<< copy and paste the script file HERE >>>>>>>>>>

```

```{r bib, include=FALSE}
# create a bib file for the R packages used in this document
knitr::write_bib(c('base', 'rmarkdown', 'tufte','ggplot2', 'kableExtra', 'ggcorrplot', 'Matrix', 'gridExtra'), file = 'skeleton.bib')
```
